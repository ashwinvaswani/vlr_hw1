{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# fpath = os.path.join(self.ann_dir, index + '.xml')\n",
    "tree = ET.parse('/Users/ashwinvaswani/Documents/vlr_hw1/q1_q2_classification/data/VOCdevkit/VOC2007/Annotations/000001.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tree.getroot()\n",
    "for elem in root:\n",
    "    # print(\"1 \", elem.tag, elem.attrib, elem.text, elem.tail)\n",
    "    # print(\"2 \",elem)\n",
    "    if elem.tag == \"object\":\n",
    "        print(\"3 \", elem[0].text, elem[3].text)\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our implementation of ResNet\n",
    "# import tqdm\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import utils\n",
    "from utils import ARGS\n",
    "import torch\n",
    "\n",
    "args = ARGS(\n",
    "        epochs=50,\n",
    "        inp_size=64,\n",
    "        # use_cuda=True,\n",
    "        use_cuda=False,\n",
    "        val_every=70,\n",
    "        lr=0.001,\n",
    "        batch_size=64,\n",
    "        step_size=30,\n",
    "        gamma=0.1\n",
    "    )\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 20)\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "\n",
    "test_loader = utils.get_data_loader(\n",
    "        'voc', train=False, batch_size=args.test_batch_size, split='test', inp_size=args.inp_size)\n",
    " \n",
    "labels = []\n",
    "# outputs = np.array([])\n",
    "features = None\n",
    "# for batch in tqdm(test_loader, desc='Running the model inference'):\n",
    "for batch_idx, (data, target, wgt) in enumerate(test_loader):\n",
    "    images = data.to(device)\n",
    "    # labels += batch['label']\n",
    "    labels.extend(target)\n",
    "    # image_paths += batch['image_path']\n",
    " \n",
    "    output = model(images)\n",
    "    print(output.shape)\n",
    "    current_outputs = output.detach().cpu().numpy()\n",
    "    if features is None:\n",
    "        features = current_outputs\n",
    "    else:\n",
    "        features = np.concatenate((features, current_outputs))\n",
    "    if batch_idx == 1:\n",
    "        break\n",
    "\n",
    "tsne = TSNE(n_components=2).fit_transform(features)\n",
    "\n",
    "# scale and move the coordinates so they fit [0; 1] range\n",
    "def scale_to_01_range(x):\n",
    "    # compute the distribution range\n",
    "    value_range = (np.max(x) - np.min(x))\n",
    " \n",
    "    # move the distribution so that it starts from zero\n",
    "    # by extracting the minimal value from all its values\n",
    "    starts_from_zero = x - np.min(x)\n",
    " \n",
    "    # make the distribution fit [0; 1] by dividing by its range\n",
    "    return starts_from_zero / value_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract x and y coordinates representing the positions of the images on T-SNE plot\n",
    "tx = tsne[:, 0]\n",
    "ty = tsne[:, 1]\n",
    " \n",
    "tx = scale_to_01_range(tx)\n",
    "ty = scale_to_01_range(ty)\n",
    "\n",
    "# initialize a matplotlib plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    " \n",
    "colors_per_class = {\n",
    "        0 : [254, 202, 87],\n",
    "    1 : [255, 107, 107],\n",
    "    2 : [10, 189, 227],\n",
    "    3 : [255, 159, 243],\n",
    "    4 : [16, 172, 132],\n",
    "    5 : [128, 80, 128],\n",
    "    6 : [87, 101, 116],\n",
    "    7 : [52, 31, 151],\n",
    "    8 : [0, 0, 0],\n",
    "    9 : [100, 100, 255],\n",
    "    10: [12, 253, 251],\n",
    "    11: [204, 69, 253],\n",
    "    12: [191, 141, 125],\n",
    "    13: [252, 100, 170],\n",
    "    14: [18, 42, 176],\n",
    "    15: [23, 109, 77],\n",
    "    16: [46, 60, 220],\n",
    "    17: [95, 108, 232],\n",
    "    18: [255, 0, 0],\n",
    "    19: [0, 255, 0],\n",
    "    # 20: [0, 0, 255]\n",
    "}\n",
    "\n",
    "# for every class, we'll add a scatter plot separately\n",
    "for label in colors_per_class:\n",
    "\n",
    "    # find the samples of the current class in the data\n",
    "    indices = [i for i, l in enumerate(labels) if np.argmax(l) == label]\n",
    " \n",
    "    # extract the coordinates of the points of this class only\n",
    "    current_tx = np.take(tx, indices)\n",
    "    current_ty = np.take(ty, indices)\n",
    " \n",
    "    # convert the class color to matplotlib format\n",
    "    color = np.array(colors_per_class[label], dtype=np.float) / 255\n",
    " \n",
    "    # add a scatter plot with the corresponding color and label\n",
    "    ax.scatter(current_tx, current_ty, color=color, label=label)\n",
    " \n",
    "# build a legend using the labels we set previously\n",
    "ax.legend(loc='best')\n",
    " \n",
    "# finally, show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
